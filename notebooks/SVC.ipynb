{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Machine Learning tests\n",
      "## Support Vector Classifier (SVC)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import libraries for **device** and **data**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import random\n",
      "import pickle\n",
      "import sklearn\n",
      "from sklearn import cross_validation\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "import pandas as pd\n",
      "from pandas import read_csv\n",
      "import numpy as np\n",
      "import csv\n",
      "import os\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import libraries for **ploting** and **visualization**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import pylab as pl\n",
      "\n",
      "#put plots in ipython notebook, inline.\n",
      "%matplotlib inline\n",
      "\n",
      "\n",
      "# MPLD3\n",
      "try:\n",
      "    import mpld3\n",
      "    from mpld3 import enable_notebook\n",
      "    from mpld3 import plugins\n",
      "    enable_notebook()\n",
      "except Exception as e:\n",
      "    print \"Attempt to import and enable mpld3 failed\", e\n",
      "    \n",
      "    \n",
      "# Seaborn\n",
      "# what would seaborn do?\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except Exception as e:\n",
      "    print \"Attempt to import and enable seaborn failed\", e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Open and show data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_training=read_csv(open('../data/training_data.csv','r'))\n",
      "df_training.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>rep_count</th>\n",
        "      <th>t (sec)</th>\n",
        "      <th>acc_x</th>\n",
        "      <th>acc_y</th>\n",
        "      <th>acc_z</th>\n",
        "      <th>gyro_x</th>\n",
        "      <th>gyro_y</th>\n",
        "      <th>gyro_z</th>\n",
        "      <th>magnet_x</th>\n",
        "      <th>magnet_y</th>\n",
        "      <th>magnet_z</th>\n",
        "      <th>set_id</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "      <td> 14343.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>  6989.360455</td>\n",
        "      <td>     0.255804</td>\n",
        "      <td>    12.615840</td>\n",
        "      <td>     0.139561</td>\n",
        "      <td>    -0.031508</td>\n",
        "      <td>    -0.100114</td>\n",
        "      <td>   482.667852</td>\n",
        "      <td>    70.292965</td>\n",
        "      <td>    66.254758</td>\n",
        "      <td>    70.043475</td>\n",
        "      <td>   258.466056</td>\n",
        "      <td>   -46.917627</td>\n",
        "      <td>    38.453183</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>  4136.625530</td>\n",
        "      <td>     1.343533</td>\n",
        "      <td>     7.248041</td>\n",
        "      <td>     0.456852</td>\n",
        "      <td>     0.863842</td>\n",
        "      <td>     0.308870</td>\n",
        "      <td>  7939.675298</td>\n",
        "      <td>  4805.114524</td>\n",
        "      <td>  9533.226909</td>\n",
        "      <td>   485.415237</td>\n",
        "      <td>   553.902397</td>\n",
        "      <td>   470.472696</td>\n",
        "      <td>    24.174969</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000080</td>\n",
        "      <td>    -1.130000</td>\n",
        "      <td>    -1.900000</td>\n",
        "      <td>    -1.200000</td>\n",
        "      <td>-32768.000000</td>\n",
        "      <td>-32752.000000</td>\n",
        "      <td>-32736.000000</td>\n",
        "      <td>-20961.280000</td>\n",
        "      <td>-20961.280000</td>\n",
        "      <td>-20961.280000</td>\n",
        "      <td>     1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>  3401.500000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     6.344000</td>\n",
        "      <td>    -0.200000</td>\n",
        "      <td>    -0.950000</td>\n",
        "      <td>    -0.260000</td>\n",
        "      <td> -1998.000000</td>\n",
        "      <td> -1435.000000</td>\n",
        "      <td> -3968.000000</td>\n",
        "      <td>  -128.800000</td>\n",
        "      <td>   -85.560000</td>\n",
        "      <td>  -182.160000</td>\n",
        "      <td>    18.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>  6987.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>    12.635763</td>\n",
        "      <td>     0.220000</td>\n",
        "      <td>     0.120000</td>\n",
        "      <td>    -0.130000</td>\n",
        "      <td>    78.000000</td>\n",
        "      <td>   116.000000</td>\n",
        "      <td>    24.000000</td>\n",
        "      <td>    88.320000</td>\n",
        "      <td>   317.400000</td>\n",
        "      <td>   -81.880000</td>\n",
        "      <td>    36.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 10572.500000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>    18.894605</td>\n",
        "      <td>     0.430000</td>\n",
        "      <td>     0.840000</td>\n",
        "      <td>     0.020000</td>\n",
        "      <td>  2506.500000</td>\n",
        "      <td>  1742.000000</td>\n",
        "      <td>  4335.000000</td>\n",
        "      <td>   225.400000</td>\n",
        "      <td>   609.960000</td>\n",
        "      <td>    67.160000</td>\n",
        "      <td>    54.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 14158.000000</td>\n",
        "      <td>    16.000000</td>\n",
        "      <td>    25.168126</td>\n",
        "      <td>     1.780000</td>\n",
        "      <td>     1.460000</td>\n",
        "      <td>     1.720000</td>\n",
        "      <td> 32752.000000</td>\n",
        "      <td> 32752.000000</td>\n",
        "      <td> 32752.000000</td>\n",
        "      <td>  2037.800000</td>\n",
        "      <td> 15722.800000</td>\n",
        "      <td> 15722.800000</td>\n",
        "      <td>    83.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 13 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "         Unnamed: 0     rep_count       t (sec)         acc_x         acc_y  \\\n",
        "count  14343.000000  14343.000000  14343.000000  14343.000000  14343.000000   \n",
        "mean    6989.360455      0.255804     12.615840      0.139561     -0.031508   \n",
        "std     4136.625530      1.343533      7.248041      0.456852      0.863842   \n",
        "min        0.000000      0.000000      0.000080     -1.130000     -1.900000   \n",
        "25%     3401.500000      0.000000      6.344000     -0.200000     -0.950000   \n",
        "50%     6987.000000      0.000000     12.635763      0.220000      0.120000   \n",
        "75%    10572.500000      0.000000     18.894605      0.430000      0.840000   \n",
        "max    14158.000000     16.000000     25.168126      1.780000      1.460000   \n",
        "\n",
        "              acc_z        gyro_x        gyro_y        gyro_z      magnet_x  \\\n",
        "count  14343.000000  14343.000000  14343.000000  14343.000000  14343.000000   \n",
        "mean      -0.100114    482.667852     70.292965     66.254758     70.043475   \n",
        "std        0.308870   7939.675298   4805.114524   9533.226909    485.415237   \n",
        "min       -1.200000 -32768.000000 -32752.000000 -32736.000000 -20961.280000   \n",
        "25%       -0.260000  -1998.000000  -1435.000000  -3968.000000   -128.800000   \n",
        "50%       -0.130000     78.000000    116.000000     24.000000     88.320000   \n",
        "75%        0.020000   2506.500000   1742.000000   4335.000000    225.400000   \n",
        "max        1.720000  32752.000000  32752.000000  32752.000000   2037.800000   \n",
        "\n",
        "           magnet_y      magnet_z        set_id  \n",
        "count  14343.000000  14343.000000  14343.000000  \n",
        "mean     258.466056    -46.917627     38.453183  \n",
        "std      553.902397    470.472696     24.174969  \n",
        "min   -20961.280000 -20961.280000      1.000000  \n",
        "25%      -85.560000   -182.160000     18.000000  \n",
        "50%      317.400000    -81.880000     36.000000  \n",
        "75%      609.960000     67.160000     54.000000  \n",
        "max    15722.800000  15722.800000     83.000000  \n",
        "\n",
        "[8 rows x 13 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_all=df_training=read_csv(open('../data/labeled_data.csv','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_holdout=read_csv(open('../data/holdout.csv','r'))\n",
      "# df_holdout.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Functions:\n",
      "\n",
      "* preparing/labeling data\n",
      "* extracting features\n",
      "* classification\n",
      "* saving output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attribution: https://gist.github.com/schlady/1576079\n",
      "\n",
      "def peakdetect(y_axis, x_axis = None, lookahead = 500, delta = 0):\n",
      "    \"\"\"\n",
      "    Converted from/based on a MATLAB script at http://billauer.co.il/peakdet.html\n",
      "    \n",
      "    Algorithm for detecting local maximas and minmias in a signal.\n",
      "    Discovers peaks by searching for values which are surrounded by lower\n",
      "    or larger values for maximas and minimas respectively\n",
      "    \n",
      "    keyword arguments:\n",
      "    y_axis -- A list containg the signal over which to find peaks\n",
      "    x_axis -- A x-axis whose values correspond to the 'y_axis' list and is used\n",
      "        in the return to specify the postion of the peaks. If omitted the index\n",
      "        of the y_axis is used. (default: None)\n",
      "    lookahead -- (optional) distance to look ahead from a peak candidate to\n",
      "        determine if it is the actual peak (default: 500) \n",
      "        '(sample / period) / f' where '4 >= f >= 1.25' might be a good value\n",
      "    delta -- (optional) this specifies a minimum difference between a peak and\n",
      "        the following points, before a peak may be considered a peak. Useful\n",
      "        to hinder the algorithm from picking up false peaks towards to end of\n",
      "        the signal. To work well delta should be set to 'delta >= RMSnoise * 5'.\n",
      "        (default: 0)\n",
      "            Delta function causes a 20% decrease in speed, when omitted\n",
      "            Correctly used it can double the speed of the algorithm\n",
      "    \n",
      "    return -- two lists [maxtab, mintab] containing the positive and negative\n",
      "        peaks respectively. Each cell of the lists contains a tupple of:\n",
      "        (position, peak_value) \n",
      "        to get the average peak value do 'np.mean(maxtab, 0)[1]' on the results\n",
      "    \"\"\"\n",
      "    maxtab = []\n",
      "    mintab = []\n",
      "    dump = []   #Used to pop the first hit which always if false\n",
      "       \n",
      "    length = len(y_axis)\n",
      "    if x_axis is None:\n",
      "        x_axis = range(length)\n",
      "    \n",
      "    #perform some checks\n",
      "    if length != len(x_axis):\n",
      "        raise ValueError, \"Input vectors y_axis and x_axis must have same length\"\n",
      "    if lookahead < 1:\n",
      "        raise ValueError, \"Lookahead must be above '1' in value\"\n",
      "    if not (np.isscalar(delta) and delta >= 0):\n",
      "        raise ValueError, \"delta must be a positive number\"\n",
      "    \n",
      "    #needs to be a numpy array\n",
      "    y_axis = np.asarray(y_axis)\n",
      "    \n",
      "    #maxima and minima candidates are temporarily stored in\n",
      "    #mx and mn respectively\n",
      "    mn, mx = np.Inf, -np.Inf\n",
      "    \n",
      "    #Only detect peak if there is 'lookahead' amount of points after it\n",
      "    for index, (x, y) in enumerate(zip(x_axis[:-lookahead], y_axis[:-lookahead])):\n",
      "        if y > mx:\n",
      "            mx = y\n",
      "            mxpos = x\n",
      "        if y < mn:\n",
      "            mn = y\n",
      "            mnpos = x\n",
      "        \n",
      "        ####look for max####\n",
      "        if y < mx-delta and mx != np.Inf:\n",
      "            #Maxima peak candidate found\n",
      "            #look ahead in signal to ensure that this is a peak and not jitter\n",
      "            if y_axis[index:index+lookahead].max() < mx:\n",
      "                maxtab.append((mxpos, mx))\n",
      "                dump.append(True)\n",
      "                #set algorithm to only find minima now\n",
      "                mx = np.Inf\n",
      "                mn = np.Inf\n",
      "        \n",
      "        ####look for min####\n",
      "        if y > mn+delta and mn != -np.Inf:\n",
      "            #Minima peak candidate found \n",
      "            #look ahead in signal to ensure that this is a peak and not jitter\n",
      "            if y_axis[index:index+lookahead].min() > mn:\n",
      "                mintab.append((mnpos, mn))\n",
      "                dump.append(False)\n",
      "                #set algorithm to only find maxima now\n",
      "                mn = -np.Inf\n",
      "                mx = -np.Inf\n",
      "    \n",
      "    \n",
      "    #Remove the false hit on the first value of the y_axis\n",
      "    try:\n",
      "        if dump[0]:\n",
      "            maxtab.pop(0)\n",
      "            #print \"pop max\"\n",
      "        else:\n",
      "            mintab.pop(0)\n",
      "            #print \"pop min\"\n",
      "        del dump\n",
      "    except IndexError:\n",
      "        #no peaks were found, should the function return empty lists?\n",
      "        pass\n",
      "    \n",
      "    return maxtab, mintab\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remap(peaks):\n",
      "    \"\"\"Reformat coordinates of peaks to properly feed into pyplot\"\"\"\n",
      "    tabs=[]\n",
      "    for tab in peaks: #mintab and maxtab\n",
      "        tab=([i[1] for i in tab],[i[0] for i in tab])\n",
      "        tabs.append(tab)\n",
      "    return tabs\n",
      "\n",
      "def get_peaks(df_x,sensor='acc',mylookahead=10):\n",
      "    deltas={'acc':.15,'gyro':2500,'magnet':15}\n",
      "    delta=deltas[sensor]\n",
      "    peak_dict={}\n",
      "    ranges={}\n",
      "    times={}\n",
      "    if sensor==\"acc\": axes=list(df_x.columns[4:7])\n",
      "    if sensor==\"gyro\": axes=list(df_x.columns[7:10])\n",
      "    if sensor==\"magnet\": axes=list(df_x.columns[10:13])\n",
      "\n",
      "    for axis in axes:\n",
      "        peaks=peakdetect(df_x[axis],df_x['t (sec)'], lookahead=mylookahead,delta=delta)\n",
      "        peaks=remap(peaks)\n",
      "        print \"%d local min, %d local max found on %s axis\" % (len(peaks[1][0]),len(peaks[0][0]),axis)\n",
      "        times[axis] = [i[1] for i in peaks]\n",
      "    return times\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make new data object\n",
      "# Get info for each rep\n",
      "# Save as feature\n",
      "#\n",
      "def make_labeled_data(df_x):\n",
      "    all_reps=[]\n",
      "    labels=[]\n",
      "    \n",
      "    # Iterate through sets\n",
      "    for mySet in range( 1 , max(df_x.set_id)+1 ):\n",
      "        \n",
      "        # get list of indexes of labeled repititions for this set\n",
      "        rep_index_list=df_x[(df_x.rep_count!=0) & (df_x.set_id==mySet)].index.tolist()\n",
      "        \n",
      "        #use list of indexes to make slices of data for each rep\n",
      "        for i in range(len(rep_index_list)):\n",
      "            \n",
      "            #Make sure not to use the last label because it has no rep after it\n",
      "            if i==len(rep_index_list)-1: break\n",
      "            \n",
      "            #Make a slice of data frame just for this repitition\n",
      "            rep_df=df_x.iloc[rep_index_list[i]:rep_index_list[i+1]+1]\n",
      "            \n",
      "            #store data about this rep\n",
      "            rep_features=[]\n",
      "            # Use columns with sensor data for analysis\n",
      "            columns=list(df_x.columns[5:14])\n",
      "            for col in columns:\n",
      "                values=rep_df.loc[:,[col]].values #get raw values for each sensor\n",
      "                \n",
      "                # Analyze values for column\n",
      "                avg=np.mean(values)\n",
      "                std=np.std(values)\n",
      "                rng=max(values) - min(values)\n",
      "                \n",
      "                #save features\n",
      "                for i in (avg,std, rng[0]):\n",
      "                    rep_features.append(round(i,2))\n",
      "                    \n",
      "            labels.append(rep_df.iloc[0].exerciseType)\n",
      "            all_reps.append(rep_features)\n",
      "                        \n",
      "    return all_reps, labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_reps(df_x,mylist):\n",
      "\n",
      "    count=0\n",
      "#     df_x=df[df.set_id==set_id]\n",
      "    for t in mylist:\n",
      "        count+=1\n",
      "        t=round(t,3)\n",
      "        indx = df_x[(df_x['t (sec)']>t-.05) & (df_x['t (sec)']<t+.05)].index.tolist()[0]\n",
      "        df_x.loc[indx,'rep_count']=count\n",
      "    return df_x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from functions import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dom_axes={'bicep curls':{'axis':'acc_y','minmax':0},\n",
      "          'tricep':{'axis':'acc_x','minmax':1},\n",
      "          'shoulder':{'axis':'acc_y','minmax':1},}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_new_data(df_x):\n",
      "    #get setid\n",
      "    df_all=read_csv(open('../data/labeled_data.csv','r'))\n",
      "    df_all.pop('Unnamed: 0')\n",
      "    setid=df_all.iloc[-1].set_id\n",
      "    setid+=1\n",
      "    df_x['set_id']=setid\n",
      "    \n",
      "    df_all=df_all.append(df_x.iloc[:])\n",
      "    df_all.to_csv('../data/labeled_data.csv')\n",
      "    \n",
      "    df_training=read_csv(open('../data/training_data.csv','r'))\n",
      "    df_training.pop('Unnamed: 0')\n",
      "    df_training=df_training.append(df_x.iloc[:])\n",
      "    df_training.to_csv('../data/training_data.csv')\n",
      "    \n",
      "    print 'saved with set_id='+str(setid)\n",
      "    \n",
      "    ##old method -commented out in case I need to bring it back\n",
      "#     #save to all data A.K.A. 'labeled_data.csv'\n",
      "#     with open('../data/labeled_data.csv','a') as labeled_csv:\n",
      "#         csv_writer=csv.writer(labeled_csv)\n",
      "#         labeled_csv.write('\\n')\n",
      "#         for i in range(len(df_x)):\n",
      "#             s=list(df_x.iloc[i])\n",
      "#             s.append(setid)\n",
      "#             s.insert(0,0)\n",
      "#             csv_writer.writerow(s)\n",
      "\n",
      "#     #save to training set\n",
      "#     with open('../data/training_data.csv','a') as labeled_csv:\n",
      "#         csv_writer=csv.writer(labeled_csv)\n",
      "#         labeled_csv.write('\\n')\n",
      "#         for i in range(len(df_x)):\n",
      "#             s=list(df_x.iloc[i])\n",
      "#             s.append(setid)\n",
      "#             s.insert(0,0)\n",
      "#             csv_writer.writerow(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# attribution for confusion matrix viz which I've modified here: \n",
      "#http://stackoverflow.com/questions/5821125/how-to-plot-confusion-matrix-with-string-axis-rather-than-integer-in-python\n",
      "\n",
      "def confusion_matrix(clf,X_test,y_test,kernel='',classifierType=''):\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "    y_pred = [clf.predict(i)[0] for i in X_test]\n",
      "    cm=confusion_matrix(y_test, y_pred, labels= clf.classes_)\n",
      "#     print cm\n",
      "#     return\n",
      "    norm_conf = []\n",
      "    for i in cm:\n",
      "        a = 0\n",
      "        tmp_arr = []\n",
      "        a = sum(i, 0)\n",
      "        for j in i:\n",
      "            tmp_arr.append(float(j)/float(a))\n",
      "        norm_conf.append(tmp_arr)\n",
      "    \n",
      "    fig = plt.figure()\n",
      "    plt.clf()\n",
      "    ax = fig.add_subplot(111)\n",
      "    ax.set_aspect(1)\n",
      "    plt.title(kernel+\" - \"+classifierType)\n",
      "    unique_conditions = clf.classes_\n",
      "    plt.xticks(np.arange(len(unique_conditions)), unique_conditions)\n",
      "    plt.yticks(np.arange(len(unique_conditions)), unique_conditions)\n",
      "    \n",
      "    res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
      "                    interpolation='nearest')\n",
      "    for i, cas in enumerate(cm):\n",
      "        for j, c in enumerate(cas):\n",
      "            if c>0:\n",
      "                plt.text(j-.2, i+.2, c, fontsize=20, color='white')\n",
      "    width = len(cm)\n",
      "    height = len(cm[0])\n",
      "    \n",
      "    # for x in xrange(width):\n",
      "    #     for y in xrange(height):\n",
      "    #         ax.annotate(str(cm[x][y]), xy=(y, x), \n",
      "    #                     horizontalalignment='center',\n",
      "    #                     verticalalignment='center')\n",
      "    \n",
      "    cb = fig.colorbar(res)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# kernels=['linear', 'poly', 'rbf', 'sigmoid'] the kernel 'precomputed' throws errors\n",
      "def test_accuracy(X_train, y_train,X_test,y_test,holdout_samples,holdout_labels, timestamp,kernel='linear'):\n",
      "    clf = svm.SVC(kernel=kernel, C=1,probability=True)\n",
      "    clf.fit(X_train, y_train)\n",
      "    clf.set_params()\n",
      "    new_metrics={'kernel':kernel}\n",
      "    print '\\n\\nkernel: '+kernel\n",
      "    metrics=['accuracy', 'f1',  'precision']\n",
      "    for metric in metrics:\n",
      "        x=list(cross_validation.cross_val_score(clf\n",
      "                                               ,X_test\n",
      "                                               ,y_test\n",
      "                                               ,cv=5\n",
      "                                               ,scoring=metric))\n",
      "        new_metrics['cross_val_'+metric]=x\n",
      "        new_metrics['cross_val_'+metric+'_avg']=sum(x)/len(x)\n",
      "        print 'cross validated average '+metric+' score: '+ str(new_metrics['cross_val_'+metric+'_avg'])\n",
      "    new_metrics['holdout']=clf.score(holdout_samples,holdout_labels)\n",
      "        \n",
      "    \n",
      "    \n",
      "#     y_true=y_test\n",
      "#     y_pred=[clf.predict(i)[0] for i in X_test]\n",
      "#     new_metrics['prfs']=list(precision_recall_fscore_support(y_true,y_pred,average='micro')[:-1])\n",
      "#     print 'test: precision,recall,f1:\\n'+str(new_metrics['prfs'])\n",
      "    \n",
      "#     y_true_holdout=holdout_labels\n",
      "#     y_pred_holdout=[clf.predict(i)[0] for i in holdout_samples]\n",
      "#     new_metrics['prfs_holdout']=list(precision_recall_fscore_support(y_true_holdout,y_pred_holdout,average='micro')[:-1])\n",
      "#     print 'holdout: precision,recall,f1:\\n'+str(new_metrics['prfs_holdout'])\n",
      "#     print y_true[0]\n",
      "#     return list(y_pred)\n",
      "    \n",
      "    print 'classification report:'\n",
      "    print classification_report(y_true, y_pred)\n",
      "    print \"\"\n",
      "\n",
      "    #confusion matrix\n",
      "    confusion_matrix(clf,X_test,y_test,kernel,classifierType='Test data')\n",
      "    \n",
      "    #save classifier\n",
      "    pickle.dump(clf,open(os.path.join('..','data','clf_archive',kernel+\"-\"+timestamp+'.p'),'wb'))\n",
      "    save_performance(new_metrics)\n",
      "    \n",
      "    return clf,new_metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_performance(new_metrics):\n",
      "    #Save model performance to model performance.csv\n",
      "    with open('../data/performance.csv','a') as perf_csv:\n",
      "        csvwriter=csv.writer(perf_csv)\n",
      "        import time\n",
      "        csvwriter.writerow([time.time()\n",
      "                            ,'add training data'\n",
      "                            ,new_metrics['kernel']\n",
      "                            ,new_metrics['cross_val_accuracy_avg']\n",
      "                            ,new_metrics['cross_val_precision_avg']\n",
      "                            ,new_metrics['cross_val_f1_avg']]\n",
      "#                            +new_metrics['prfs']+new_metrics['prfs_holdout']\n",
      "                            )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### One Step build function\n",
      "\n",
      "* Currently used for adding training data\n",
      "* Future: use to optimize features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_model(new_csv=''):\n",
      "    \"\"\"One step to add new training data to model and output results.\"\"\"\n",
      "    if new_csv!='':\n",
      "        #convert to DataFrame\n",
      "        print 'getting new training data'\n",
      "        df_x=read_csv(new_csv)\n",
      "        \n",
      "        #find and label peaks based on exerciseType\n",
      "        print 'labeling repetitions'\n",
      "        exerciseType=df_x.iloc[0].exerciseType\n",
      "        \n",
      "        times=get_peaks(df_x,mylookahead=5)\n",
      "    \n",
      "        rep_times=times[dom_axes[exerciseType]['axis']][dom_axes[exerciseType]['minmax']]\n",
      "        df_x=add_reps(df_x,rep_times)\n",
      "        #possibly show where the peaks were added - VIZ\n",
      "        \n",
      "        #add to labeled_data.csv and training_data.csv\n",
      "        print 'saving new, labeled data with entire training set'\n",
      "        save_new_data(df_x)\n",
      "    \n",
      "    #Teach classifier\n",
      "    print 'opening training and holdout sets'\n",
      "    df_training=read_csv(open('../data/training_data.csv','r'))\n",
      "    df_holdout=read_csv(open('../data/holdout.csv','r'))\n",
      "    print 'determining features'\n",
      "    all_reps, labels = make_labeled_data(df_training)\n",
      "    holdout_samples, holdout_labels=make_labeled_data(df_holdout)\n",
      "    print '\\ncross validation and testing'\n",
      "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(all_reps,\n",
      "        labels, \n",
      "        random_state=0)\n",
      "    timestamp=time.ctime().replace(\":\",\"-\")\n",
      "    kernels=['linear'] # the kernel 'precomputed' throws errors\n",
      "    for kern in kernels:\n",
      "        clf,new_metrics=test_accuracy(X_train\n",
      "                                      , y_train\n",
      "                                      ,X_test\n",
      "                                      ,y_test\n",
      "                                      ,holdout_samples\n",
      "                                      ,holdout_labels\n",
      "                                      ,kernel=kern\n",
      "                                      ,timestamp=timestamp,)\n",
      "    \n",
      "    \n",
      "    \n",
      "    #use all possible data to make best classifier\n",
      "    \n",
      "    df_all=read_csv(open('../data/labeled_data.csv','r'))\n",
      "    all_reps, labels = make_labeled_data(df_all)\n",
      "    clf_final = sklearn.svm.SVC(kernel='linear', C=1,probability=True)\n",
      "    clf_final.fit(all_reps, labels)\n",
      "    \n",
      "    #save new classifer model\n",
      "    pickle.dump(clf_final,open('../svc_model.p','wb'))\n",
      "    print 'saved model'\n",
      "    #Verification with testing data and hold out\n",
      "    \n",
      "\n",
      "    return clf, new_metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Make new classifier using make_model()\n",
      "\n",
      "* **no arguments** - use existing data.\n",
      "* **file path given** - import csv at given path to training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# csf,new_metrics=make_model('../data/new_training.csv')\n",
      "csf,new_metrics=make_model()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "opening training and holdout sets\n",
        "determining features\n",
        "\n",
        "cross validation and testing"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "\n",
        "kernel: linear"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cross validated average accuracy score: 0.925517241379"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cross validated average f1 score: 0.92826488917"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cross validated average precision score: 0.94258347017"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "### ***Debugging code below***"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get features and labels\n",
      "all_reps, labels = make_labeled_data(df_training)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 446
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "holdout_samples, holdout_labels=make_labeled_data(df_holdout)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 294
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(all_reps,\n",
      "    labels, \n",
      "    random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf,new_metrics=test_accuracy(X_train, y_train,X_test,y_test,holdout_samples,holdout_labels,kernel='linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "kernel: linear\n",
        "cross validated average accuracy score: 0.898148148148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "cross validated average f1 score: 0.897592106332"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "cross validated average precision score: 0.907141306665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "test: precision,recall,f1:\n",
        "[0.98550724637681164, 0.98550724637681164, 0.98550724637681164]\n",
        "holdout: precision,recall,f1:\n",
        "[1.0, 1.0, 1.0]\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "bicep curls       1.00      0.97      0.99        39\n",
        "   shoulder       0.97      1.00      0.98        58\n",
        "     tricep       1.00      0.98      0.99        41\n",
        "\n",
        "avg / total       0.99      0.99      0.99       138\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 342
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 336,
       "text": [
        "{'cross_val_accuracy': [0.8928571428571429,\n",
        "  0.9285714285714286,\n",
        "  0.9285714285714286,\n",
        "  0.88888888888888884,\n",
        "  0.85185185185185186],\n",
        " 'cross_val_accuracy_avg': 0.89814814814814814,\n",
        " 'cross_val_f1': [0.89000000000000001,\n",
        "  0.92929292929292928,\n",
        "  0.92708333333333326,\n",
        "  0.88954248366013078,\n",
        "  0.85204178537511854],\n",
        " 'cross_val_f1_avg': 0.89759210633230246,\n",
        " 'cross_val_precision': [0.89050235478806905,\n",
        "  0.94285714285714284,\n",
        "  0.93956043956043955,\n",
        "  0.90123456790123457,\n",
        "  0.86155202821869492],\n",
        " 'cross_val_precision_avg': 0.90714130666511628,\n",
        " 'holdout': 1.0,\n",
        " 'kernel': 'linear',\n",
        " 'prfs': [0.98550724637681164, 0.98550724637681164, 0.98550724637681164],\n",
        " 'prfs_holdout': [1.0, 1.0, 1.0]}"
       ]
      }
     ],
     "prompt_number": 336
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Best kernel is **Linear** but **poly** is almost as good"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_final = sklearn.svm.SVC(kernel='linear', C=1,probability=True)\n",
      "clf_final.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 175,
       "text": [
        "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Test any random rep"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_rep=random.randint(1,len(all_reps))\n",
      "print 'repitition #'+str(random_rep)\n",
      "print \"classifier's guess: \"+clf_final.predict(all_reps[random_rep])[0]\n",
      "print \"actual label:       \"+labels[random_rep]\n",
      "# What probability\n",
      "print \"%prob 'tricep', %prob 'shoulder', %prob 'bicep curls'\"\n",
      "print clf_final.predict_proba(all_reps[random_rep])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "repitition #230\n",
        "classifier's guess: shoulder\n",
        "actual label:       shoulder\n",
        "%prob 'tricep', %prob 'shoulder', %prob 'bicep curls'\n",
        "[  5.88610465e-07   9.99821096e-01   1.78315825e-04]\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_reps[random_rep]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[-0.53,\n",
        " 0.15,\n",
        " 0.47,\n",
        " 0.17,\n",
        " 0.55,\n",
        " 1.54,\n",
        " -0.24,\n",
        " 0.17,\n",
        " 0.44,\n",
        " -125.5,\n",
        " 5664.76,\n",
        " 17515.0,\n",
        " -288.81,\n",
        " 7329.64,\n",
        " 23406.0,\n",
        " -361.56,\n",
        " 15447.15,\n",
        " 44707.0,\n",
        " 394.33,\n",
        " 159.77,\n",
        " 481.16,\n",
        " 101.72,\n",
        " 266.52,\n",
        " 724.04,\n",
        " 256.91,\n",
        " 64.74,\n",
        " 188.6]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How much time does it take to predict? Must be less than 100ms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit(clf_final.predict(all_reps[sample_ind])[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 70.9 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "70.9 microseconds is less than 1 ms so it's good  :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load all data into classifier for use with new data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump(clf_final,open('../svc_model.p','wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model=pickle.load(open('../svc_model.p'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(model.support_vectors_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "25"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}