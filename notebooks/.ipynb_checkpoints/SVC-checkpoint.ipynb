{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Machine Learning tests\n",
      "## Support Vector Classifier (SVC)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import libraries for **device** and **data**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import random\n",
      "import pickle\n",
      "import sklearn\n",
      "import pandas as pd\n",
      "from pandas import read_csv\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import libraries for **ploting** and **visualization**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import pylab as pl\n",
      "\n",
      "#put plots in ipython notebook, inline.\n",
      "%matplotlib inline\n",
      "\n",
      "\n",
      "# MPLD3\n",
      "try:\n",
      "    import mpld3\n",
      "    from mpld3 import enable_notebook\n",
      "    from mpld3 import plugins\n",
      "    enable_notebook()\n",
      "except Exception as e:\n",
      "    print \"Attempt to import and enable mpld3 failed\", e\n",
      "    \n",
      "    \n",
      "# Seaborn\n",
      "# what would seaborn do?\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except Exception as e:\n",
      "    print \"Attempt to import and enable seaborn failed\", e"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Open and show data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_training=read_csv(open('training_data.csv','r'))\n",
      "df_training.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'training_data.csv'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-2de984a53ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'training_data.csv'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_holdout=read_csv(open('../data/holdout.csv','r'))\n",
      "# df_holdout.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Extract features from labelled data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make new data object\n",
      "# Get info for each rep\n",
      "# Save as feature\n",
      "#\n",
      "def make_labeled_data(df_x):\n",
      "    all_reps=[]\n",
      "    labels=[]\n",
      "    \n",
      "    # Iterate through sets\n",
      "    for mySet in range( 1 , max(df_x.set_id)+1 ):\n",
      "        \n",
      "        # get list of indexes of labeled repititions for this set\n",
      "        rep_index_list=df_x[(df_x.rep_count!=0) & (df_x.set_id==mySet)].index.tolist()\n",
      "        \n",
      "        #use list of indexes to make slices of data for each rep\n",
      "        for i in range(len(rep_index_list)):\n",
      "            \n",
      "            #Make sure not to use the last label because it has no rep after it\n",
      "            if i==len(rep_index_list)-1: break\n",
      "            \n",
      "            #Make a slice of data frame just for this repitition\n",
      "            rep_df=df_x.iloc[rep_index_list[i]:rep_index_list[i+1]+1]\n",
      "            \n",
      "            #store data about this rep\n",
      "            rep_features=[]\n",
      "            # Use columns with sensor data for analysis\n",
      "            columns=list(df_x.columns[5:14])\n",
      "            for col in columns:\n",
      "                values=rep_df.loc[:,[col]].values #get raw values for each sensor\n",
      "                \n",
      "                # Analyze values for column\n",
      "                avg=np.mean(values)\n",
      "                std=np.std(values)\n",
      "                rng=max(values) - min(values)\n",
      "                \n",
      "                #save features\n",
      "                for i in (avg,std, rng[0]):\n",
      "                    rep_features.append(round(i,2))\n",
      "                    \n",
      "            labels.append(rep_df.iloc[0].exerciseType)\n",
      "            all_reps.append(rep_features)\n",
      "                        \n",
      "    return all_reps, labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d={'magnet': (-70.84, 503.24, 83.72), 'gyro': (-37, -37, 74), 'accel': (0.28, -0.04, -0.89), 'time': 1398637579.47}\n",
      "def to_df(d):\n",
      "    d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "***notes on selected features***\n",
      "\n",
      "* Average values vary even between the same type of exercise - so it was removed as a feature"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_reps, labels = make_labeled_data(df_training)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "holdout_samples, holdout_labels=make_labeled_data(df_holdout)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(all_reps,\n",
      "    labels, \n",
      "    random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'cross_validation'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-ca49468c8938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(all_reps,\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     random_state=0)\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'cross_validation'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Test for best kernel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kernels=['linear', 'poly', 'rbf', 'sigmoid'] # the kernel 'precomputed' throws errors\n",
      "for kern in kernels:\n",
      "    clf = sklearn.svm.SVC(kernel=kern, C=1)\n",
      "    clf.fit(X_train, y_train)\n",
      "    clf.set_params(probability=True)\n",
      "    print kern\n",
      "    print 'cross validated score: '+ str(cross_validation.cross_val_score(clf,\n",
      "                                                                          X_test,\n",
      "                                                                          y_test,\n",
      "                                                                          cv=5))\n",
      "    print 'holdout score: '+str(clf.score(holdout_samples,holdout_labels))\n",
      "    print ''\n",
      "#     print(classification_report(y_true, y_pred, target_names=target_names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'svm'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-bbb91f83ca76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'poly'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# the kernel 'precomputed' throws errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkern\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'svm'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Best kernel is **Linear** but **poly** is almost as good"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_final = sklearn.svm.SVC(kernel='linear', C=1)\n",
      "clf_final.fit(X_train, y_train)\n",
      "clf_final.set_params(probability=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "y_true = y_test\n",
      "y_pred = [clf_final.predict(i)[0] for i in X_test]\n",
      "cm=confusion_matrix(y_true, y_pred)\n",
      "print cm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[40  0  0]\n",
        " [ 0 36  0]\n",
        " [ 0  0 34]]\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Show confusion matrix in a separate window\n",
      "# pl.matshow(cm)\n",
      "# pl.title('Confusion matrix')\n",
      "# pl.colorbar()\n",
      "# pl.ylabel('True label')\n",
      "# pl.xlabel('Predicted label')\n",
      "# pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Test any random rep"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_rep=random.randint(1,len(all_reps))\n",
      "print 'repitition #'+str(random_rep)\n",
      "print \"classifier's guess: \"+clf_final.predict(all_reps[sample_ind])[0]\n",
      "print \"actual label:       \"+labels[sample_ind]\n",
      "# What probability\n",
      "print \"%prob 'tricep', %prob 'shoulder', %prob 'bicep curls'\"\n",
      "print clf_final.predict_proba(all_reps[sample_ind])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "repitition #212\n",
        "classifier's guess: tricep\n",
        "actual label:       tricep\n",
        "%prob 'tricep', %prob 'shoulder', %prob 'bicep curls'\n",
        "[ 0.5152186   0.38087395  0.10390744]\n"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How much time does it take to predict? Must be less than 100ms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit(clf_final.predict(all_reps[sample_ind])[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 70.9 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "70.9 microseconds is less than 1 ms so it's good  :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load all data into classifier for use with new data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump(clf_final,open('svc_model.p','wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}